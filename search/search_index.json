{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Furiosa Artifacts This repository provides deep learning models provided by FuriosaAI. Available models are described in artifacts.py which is a descriptor file in the form defined by furiosa-registry Installation Load models via furiosa-models . pip install furiosa-models Building from Source git clone https://github.com/furiosa-ai/furiosa-artifacts pip install . Example from furiosa.registry import Model from furiosa.models.vision import MLCommonsResNet50 model : Model = MLCommonsResNet50 () ... Testing Before contributing, we recommend you to write end-to-end testing codes under ./scripts/ directory. And please run the tests using the following script: # Install the test dependency first pip install . [ test ] # Run test pytest ./scripts License Copyright (c) 2021 FuriosaAI Inc. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"Overview"},{"location":"#furiosa-artifacts","text":"This repository provides deep learning models provided by FuriosaAI. Available models are described in artifacts.py which is a descriptor file in the form defined by furiosa-registry","title":"Furiosa Artifacts"},{"location":"#installation","text":"Load models via furiosa-models . pip install furiosa-models","title":"Installation"},{"location":"#building-from-source","text":"git clone https://github.com/furiosa-ai/furiosa-artifacts pip install .","title":"Building from Source"},{"location":"#example","text":"from furiosa.registry import Model from furiosa.models.vision import MLCommonsResNet50 model : Model = MLCommonsResNet50 () ...","title":"Example"},{"location":"#testing","text":"Before contributing, we recommend you to write end-to-end testing codes under ./scripts/ directory. And please run the tests using the following script: # Install the test dependency first pip install . [ test ] # Run test pytest ./scripts","title":"Testing"},{"location":"#license","text":"Copyright (c) 2021 FuriosaAI Inc. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"changelog/","text":"Changelog All notable changes to this project will be documented in this file. The format is based on keep a changelog . [Unreleased] [0.0.3] Added Changed Furiosa Model now uses blocking API by default instead of non-blocking API [0.0.2] [0.0.1]","title":"Changelog"},{"location":"changelog/#changelog","text":"All notable changes to this project will be documented in this file. The format is based on keep a changelog .","title":"Changelog"},{"location":"changelog/#unreleased","text":"","title":"[Unreleased]"},{"location":"changelog/#003","text":"","title":"[0.0.3]"},{"location":"changelog/#added","text":"","title":"Added"},{"location":"changelog/#changed","text":"Furiosa Model now uses blocking API by default instead of non-blocking API","title":"Changed"},{"location":"changelog/#002","text":"","title":"[0.0.2]"},{"location":"changelog/#001","text":"","title":"[0.0.1]"},{"location":"models/","text":"Available models List Image Classification ResNet50-v1.5 Object detection SSD-ResNet34 SSD-MobileNets-v1 Details artifacts.py","title":"Available models"},{"location":"models/#available-models","text":"","title":"Available models"},{"location":"models/#list","text":"","title":"List"},{"location":"models/#image-classification","text":"ResNet50-v1.5","title":"Image Classification"},{"location":"models/#object-detection","text":"SSD-ResNet34 SSD-MobileNets-v1","title":"Object detection"},{"location":"models/#details","text":"artifacts.py","title":"Details"},{"location":"models/efficientnet_v2_m/","text":"EfficientNet v2 M","title":"EfficientNet v2 M"},{"location":"models/efficientnet_v2_m/#efficientnet-v2-m","text":"","title":"EfficientNet v2 M"},{"location":"models/efficientnet_v2_s/","text":"EfficientNet v2 S","title":"EfficientNet v2 S"},{"location":"models/efficientnet_v2_s/#efficientnet-v2-s","text":"","title":"EfficientNet v2 S"},{"location":"models/resnet50_v1.5/","text":"ResNet50 v1.5","title":"ResNet50 v1.5"},{"location":"models/resnet50_v1.5/#resnet50-v15","text":"","title":"ResNet50 v1.5"},{"location":"models/ssd_mobilenet_v1/","text":"SSD MobileNet v1","title":"SSD MobileNet v1"},{"location":"models/ssd_mobilenet_v1/#ssd-mobilenet-v1","text":"","title":"SSD MobileNet v1"},{"location":"models/ssd_resnet34/","text":"SSD ResNet34","title":"SSD ResNet34"},{"location":"models/ssd_resnet34/#ssd-resnet34","text":"","title":"SSD ResNet34"},{"location":"usage/loading/","text":"Loading models You can load models provided by Furiosa Artifacts using furiosa-models which based on furiosa-registry . Example Blocking and Non-Blocking API Furiosa Model offers both blocking and non-blocking API for fetching models. Blocking example from furiosa.models.vision import ResNet18 from furiosa.registry import Model model : Model = ResNet18 ( pretrained = True ) print ( model . name ) print ( model . format ) print ( model . metadata . description ) Non-blocking example import asyncio from furiosa.models.nonblocking.vision import ResNet18 from furiosa.registry import Model model : Model = asyncio . run ( ResNet18 ( pretrained = True )) print ( model . name ) print ( model . format ) print ( model . metadata . description ) What's going on here: ResNet18(pretrained=True) Create model instance. This function ultimately calls the function entrypoint which provided by artifacts.py in furiosa-artifacts If pretrained=True is set, a model with pre-trained weights will be fetched. pretrained=True is a default option as well as the only-allowed option for now. You can also find more arguments in the model class. For non-blocking example asyncio.run() furiosa.models.nonblocking module offers non-blocking API. When you are writing codes using furiosa-models in async functions or async eventloop, you should use the non-blocking APIs.","title":"Loading models"},{"location":"usage/loading/#loading-models","text":"You can load models provided by Furiosa Artifacts using furiosa-models which based on furiosa-registry .","title":"Loading models"},{"location":"usage/loading/#example","text":"","title":"Example"},{"location":"usage/loading/#blocking-and-non-blocking-api","text":"Furiosa Model offers both blocking and non-blocking API for fetching models.","title":"Blocking and Non-Blocking API"},{"location":"usage/loading/#blocking-example","text":"from furiosa.models.vision import ResNet18 from furiosa.registry import Model model : Model = ResNet18 ( pretrained = True ) print ( model . name ) print ( model . format ) print ( model . metadata . description )","title":"Blocking example"},{"location":"usage/loading/#non-blocking-example","text":"import asyncio from furiosa.models.nonblocking.vision import ResNet18 from furiosa.registry import Model model : Model = asyncio . run ( ResNet18 ( pretrained = True )) print ( model . name ) print ( model . format ) print ( model . metadata . description ) What's going on here: ResNet18(pretrained=True) Create model instance. This function ultimately calls the function entrypoint which provided by artifacts.py in furiosa-artifacts If pretrained=True is set, a model with pre-trained weights will be fetched. pretrained=True is a default option as well as the only-allowed option for now. You can also find more arguments in the model class. For non-blocking example asyncio.run() furiosa.models.nonblocking module offers non-blocking API. When you are writing codes using furiosa-models in async functions or async eventloop, you should use the non-blocking APIs.","title":"Non-blocking example"},{"location":"usage/publishing/","text":"Publishing models Furiosa Artifacts use model class in furiosa-registry to publish models. furiosa-registry will find available models via a descriptor file named artifacts.py . To publish models, as a model provider you need to add function entrypoints which returns a model instance in artifacts.py Since github is not suitable for storing large data files, please use DVC for such purpose. A detailed description can be found on this section Example artifacts.py from typing import Any from furiosa.registry import Format , Metadata , Model , Publication from furiosa.registry.client.transport import FileTransport loader = FileTransport () class ResNet18_Model ( Model ): \"\"\"# This docstring shows up in furisao.registry.help() ResNet 18 model # Additional arguments pretrained (bool): kwargs, load pretrained weights into th model \"\"\" def __init__ ( self , pretrained : bool ): ... def preprocess ( self , * args : Any , ** kwargs : Any ) -> Any : ... def postprocess ( self , * args : Any , ** kwargs : Any ) -> Any : ... async def ResNet18 ( * args : Any , ** kwargs : Any ) -> ResNet18_Model : return ResNet18_Model ( name = \"ResNet18\" , model = await loader . read ( \"models/resnet18.onnx\" ), format = Format . ONNX , family = \"ResNet\" , version = \"v1.0\" , metadata = Metadata ( description = \"Model description\" , publication = Publication ( url = \"Model publication URL\" ), ), ** kwargs , ) What's going on here: class ResNet18_Model(Model) Model class implements furiosa.registry.Model . furiosa.registry.Model is a class which you have to implement to publish your model. This model class is based on a pydantic Model and have several required fields to fill including: name model name. model model binary bytes. format model binary format. \"onnx\" or \"tflite\" are supported. def preprocess(self, *args: Any, **kwargs: Any) -> Any def postprocess(self, *args: Any, **kwargs: Any) -> Any Additional functions to support model modification. As a model provider, you can add pre-process, post-process functions to provide model specific functionalities. Note that this custom functions are not defined via interface which means you can add any custom functions. As users does not know which functions are provided, you have to document these functions to allow clients to use models correctly. async def ResNet18(*args: Any, **kwargs: Any) -> ResNet18_Model Function entrypoint which will be called from furiosa-registry . model=await loader.read(\"models/resnet18.onnx\") Loading model binary bytes via furiosa.registry.client.transport . You may use different ways to load binary bytes depending on how you maintain your model binary. How to use DVC for Furiosa Artifacts DVC Model binary files(e.g. *.onnx , *.tflite ) are usually too large for github to process. Therefore we handle these files with DVC , a version control system specialized for handling ML models and data sets. DVC installation You can install DVC by following this instruction . You probably need dvc[s3] python package since this repository uses s3 as DVC's backend. DVC pipelines Since DVC does not support anonymous logins & downloads for s3 backend ( related issue ), we have separated endpoints by purpose. You can also refer to the actual configuration file . origin backend An https endpoint. We use this endpoint to download files without any AWS credentials. s3origin backend An s3 protocol endpoint. We use this endpoint to upload files to s3 bucket. Download model files via DVC # `origin` is specified in [.dvc/config](.dvc/config), # -j option specifies num of parallel downloads $ dvc pull -r origin -j 10 Add a new data via DVC # `s3origin` is specified in [.dvc/config](.dvc/config), # We use `s3origin` remote as DVC does not currently support uploading files via https endpoint $ touch ./models/example-model $ dvc add -R ./models/example-model $ dvc push -r s3origin # Please follow DVC's instructions to follow these changes with git","title":"Publishing models"},{"location":"usage/publishing/#publishing-models","text":"Furiosa Artifacts use model class in furiosa-registry to publish models. furiosa-registry will find available models via a descriptor file named artifacts.py . To publish models, as a model provider you need to add function entrypoints which returns a model instance in artifacts.py Since github is not suitable for storing large data files, please use DVC for such purpose. A detailed description can be found on this section","title":"Publishing models"},{"location":"usage/publishing/#example","text":"artifacts.py from typing import Any from furiosa.registry import Format , Metadata , Model , Publication from furiosa.registry.client.transport import FileTransport loader = FileTransport () class ResNet18_Model ( Model ): \"\"\"# This docstring shows up in furisao.registry.help() ResNet 18 model # Additional arguments pretrained (bool): kwargs, load pretrained weights into th model \"\"\" def __init__ ( self , pretrained : bool ): ... def preprocess ( self , * args : Any , ** kwargs : Any ) -> Any : ... def postprocess ( self , * args : Any , ** kwargs : Any ) -> Any : ... async def ResNet18 ( * args : Any , ** kwargs : Any ) -> ResNet18_Model : return ResNet18_Model ( name = \"ResNet18\" , model = await loader . read ( \"models/resnet18.onnx\" ), format = Format . ONNX , family = \"ResNet\" , version = \"v1.0\" , metadata = Metadata ( description = \"Model description\" , publication = Publication ( url = \"Model publication URL\" ), ), ** kwargs , ) What's going on here: class ResNet18_Model(Model) Model class implements furiosa.registry.Model . furiosa.registry.Model is a class which you have to implement to publish your model. This model class is based on a pydantic Model and have several required fields to fill including: name model name. model model binary bytes. format model binary format. \"onnx\" or \"tflite\" are supported. def preprocess(self, *args: Any, **kwargs: Any) -> Any def postprocess(self, *args: Any, **kwargs: Any) -> Any Additional functions to support model modification. As a model provider, you can add pre-process, post-process functions to provide model specific functionalities. Note that this custom functions are not defined via interface which means you can add any custom functions. As users does not know which functions are provided, you have to document these functions to allow clients to use models correctly. async def ResNet18(*args: Any, **kwargs: Any) -> ResNet18_Model Function entrypoint which will be called from furiosa-registry . model=await loader.read(\"models/resnet18.onnx\") Loading model binary bytes via furiosa.registry.client.transport . You may use different ways to load binary bytes depending on how you maintain your model binary.","title":"Example"},{"location":"usage/publishing/#how-to-use-dvc-for-furiosa-artifacts","text":"","title":"How to use DVC for Furiosa Artifacts"},{"location":"usage/publishing/#dvc","text":"Model binary files(e.g. *.onnx , *.tflite ) are usually too large for github to process. Therefore we handle these files with DVC , a version control system specialized for handling ML models and data sets.","title":"DVC"},{"location":"usage/publishing/#dvc-installation","text":"You can install DVC by following this instruction . You probably need dvc[s3] python package since this repository uses s3 as DVC's backend.","title":"DVC installation"},{"location":"usage/publishing/#dvc-pipelines","text":"Since DVC does not support anonymous logins & downloads for s3 backend ( related issue ), we have separated endpoints by purpose. You can also refer to the actual configuration file . origin backend An https endpoint. We use this endpoint to download files without any AWS credentials. s3origin backend An s3 protocol endpoint. We use this endpoint to upload files to s3 bucket. Download model files via DVC # `origin` is specified in [.dvc/config](.dvc/config), # -j option specifies num of parallel downloads $ dvc pull -r origin -j 10 Add a new data via DVC # `s3origin` is specified in [.dvc/config](.dvc/config), # We use `s3origin` remote as DVC does not currently support uploading files via https endpoint $ touch ./models/example-model $ dvc add -R ./models/example-model $ dvc push -r s3origin # Please follow DVC's instructions to follow these changes with git","title":"DVC pipelines"},{"location":"usage/running/","text":"Running models You can run inference via models provided by Furiosa Artifacts using furiosa-runtime . Example import asyncio from furiosa.models.vision import ResNet18 from furiosa.registry import Model from furiosa.runtime import session model : Model = ResNet18 () with session . create ( model . model , compile_config = model . compiler_config ) as sess : # Load input data data = ... # Pre-process the input data via provided preprocess function by furiosa-artifacts input = model . preprocess ( data ) # Run the inference output = sess . run ( input ) # Post-process the output data via provided preprocess function by furiosa-artifacts final_output = model . postprocess ( output ) with session.create(model.model, compile_config=model.compiler_config) as sess: Session in furiosa-runtime needs model binary when creating the session. As models provided by furiosa-models have model field which is bytes formatted model binary, you can pass the model into the session. Furiosa Artifacts also provides recommended compiler configurations for some models. You can pass the model.compiler_config variable when creating a session. Of course you can pass your own compiler configuration as well. input = model.preprocess(data) final_output = model.postprocess(output) Model pre/post processing via the functions provided by Furiosa Artifacts. There may be other functions in Model class provided by model providers. As a model client, you should find the documents to find which functions are available. output = sess.run(input) Run inference via the session. More references You can find Furiosa runtime API references and examples in SDK documentation","title":"Running models"},{"location":"usage/running/#running-models","text":"You can run inference via models provided by Furiosa Artifacts using furiosa-runtime .","title":"Running models"},{"location":"usage/running/#example","text":"import asyncio from furiosa.models.vision import ResNet18 from furiosa.registry import Model from furiosa.runtime import session model : Model = ResNet18 () with session . create ( model . model , compile_config = model . compiler_config ) as sess : # Load input data data = ... # Pre-process the input data via provided preprocess function by furiosa-artifacts input = model . preprocess ( data ) # Run the inference output = sess . run ( input ) # Post-process the output data via provided preprocess function by furiosa-artifacts final_output = model . postprocess ( output ) with session.create(model.model, compile_config=model.compiler_config) as sess: Session in furiosa-runtime needs model binary when creating the session. As models provided by furiosa-models have model field which is bytes formatted model binary, you can pass the model into the session. Furiosa Artifacts also provides recommended compiler configurations for some models. You can pass the model.compiler_config variable when creating a session. Of course you can pass your own compiler configuration as well. input = model.preprocess(data) final_output = model.postprocess(output) Model pre/post processing via the functions provided by Furiosa Artifacts. There may be other functions in Model class provided by model providers. As a model client, you should find the documents to find which functions are available. output = sess.run(input) Run inference via the session.","title":"Example"},{"location":"usage/running/#more-references","text":"You can find Furiosa runtime API references and examples in SDK documentation","title":"More references"}]}